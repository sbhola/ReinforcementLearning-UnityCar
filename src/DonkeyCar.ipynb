{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\gym6\\lib\\site-packages\\skimage\\viewer\\utils\\core.py:10: UserWarning: Recommended matplotlib backend is `Agg` for full skimage.viewer functionality.\n",
      "  warn(\"Recommended matplotlib backend is `Agg` for full \"\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import gym\n",
    "import random\n",
    "import numpy as np\n",
    "import cv2\n",
    "import skimage as skimage\n",
    "#import skimage as skimage\n",
    "from skimage import transform, color, exposure\n",
    "from skimage.transform import rotate\n",
    "from skimage.viewer import ImageViewer\n",
    "from collections import deque\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Sequential\n",
    "from keras.initializers import normal, identity\n",
    "from keras.models import model_from_json\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "\n",
    "import donkey_gym\n",
    "import my_cv\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "EPISODES = 1000\n",
    "img_rows , img_cols = 80, 80\n",
    "# Convert image into Black and white\n",
    "img_channels = 4 # We stack 4 frames\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQNAgent:\n",
    "\n",
    "    def __init__(self, state_size, action_size):\n",
    "        self.t = 0\n",
    "        self.max_Q = 0\n",
    "        self.train = True\n",
    "        self.lane_detection = False # Set to True to train on images with segmented lane lines\n",
    "\n",
    "        # Get size of state and action\n",
    "        self.state_size = state_size\n",
    "        self.action_size = action_size\n",
    "\n",
    "        # These are hyper parameters for the DQN\n",
    "        self.discount_factor = 0.99\n",
    "        self.learning_rate = 1e-4\n",
    "        if (self.train):\n",
    "            self.epsilon = 1.0\n",
    "            self.initial_epsilon = 1.0\n",
    "        else:\n",
    "            self.epsilon = 1e-6\n",
    "            self.initial_epsilon = 1e-6\n",
    "        self.epsilon_min = 0.02\n",
    "        self.batch_size = 64\n",
    "        self.train_start = 100\n",
    "        self.explore = 10000\n",
    "\n",
    "        # Create replay memory using deque\n",
    "        self.memory = deque(maxlen=10000)\n",
    "\n",
    "        # Create main model and target model\n",
    "        self.model = self.build_model()\n",
    "        self.target_model = self.build_model()\n",
    "\n",
    "        # Copy the model to target model\n",
    "        # --> initialize the target model so that the parameters of model & target model to be same\n",
    "        self.update_target_model()\n",
    "\n",
    "    def build_model(self):\n",
    "        print(\"Now we build the model\")\n",
    "        model = Sequential()\n",
    "        model.add(Convolution2D(32, 8, 8, subsample=(4, 4), border_mode='same',input_shape=(img_rows,img_cols,img_channels)))  #80*80*4\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(Convolution2D(64, 4, 4, subsample=(2, 2), border_mode='same'))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(Convolution2D(64, 3, 3, subsample=(1, 1), border_mode='same'))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(512))\n",
    "        model.add(Activation('relu'))\n",
    "\n",
    "        # 15 categorical bins for Steering angles\n",
    "        model.add(Dense(15, activation=\"linear\")) \n",
    "\n",
    "        adam = Adam(lr=self.learning_rate)\n",
    "        model.compile(loss='mse',optimizer=adam)\n",
    "        print(\"We finished building the model\")\n",
    "\n",
    "        return model\n",
    "\n",
    "    def process_image(self, obs):\n",
    "\n",
    "        if not agent.lane_detection:\n",
    "            obs = skimage.color.rgb2gray(obs)\n",
    "            obs = skimage.transform.resize(obs, (img_rows, img_cols))\n",
    "            return obs\n",
    "        else:\n",
    "            obs = cv2.cvtColor(obs, cv2.COLOR_BGR2GRAY)\n",
    "            obs = cv2.resize(obs, (img_rows, img_cols))\n",
    "            edges = my_cv.detect_edges(obs, low_threshold=50, high_threshold=150)\n",
    "\n",
    "            rho = 0.8\n",
    "            theta = np.pi/180\n",
    "            threshold = 25\n",
    "            min_line_len = 5\n",
    "            max_line_gap = 10\n",
    "\n",
    "            hough_lines = my_cv.hough_lines(edges, rho, theta, threshold, min_line_len, max_line_gap)\n",
    "\n",
    "            left_lines, right_lines = my_cv.separate_lines(hough_lines)\n",
    "\n",
    "            filtered_right, filtered_left = [],[]\n",
    "            if len(left_lines):\n",
    "                filtered_left = my_cv.reject_outliers(left_lines, cutoff=(-30.0, -0.1), lane='left')\n",
    "            if len(right_lines):\n",
    "                filtered_right = my_cv.reject_outliers(right_lines,  cutoff=(0.1, 30.0), lane='right')\n",
    "\n",
    "            lines = []\n",
    "            if len(filtered_left) and len(filtered_right):\n",
    "                lines = np.expand_dims(np.vstack((np.array(filtered_left),np.array(filtered_right))),axis=0).tolist()\n",
    "            elif len(filtered_left):\n",
    "                lines = np.expand_dims(np.expand_dims(np.array(filtered_left),axis=0),axis=0).tolist()\n",
    "            elif len(filtered_right):\n",
    "                lines = np.expand_dims(np.expand_dims(np.array(filtered_right),axis=0),axis=0).tolist()\n",
    "\n",
    "            ret_img = np.zeros((80,80))\n",
    "\n",
    "            if len(lines):\n",
    "                try:\n",
    "                    my_cv.draw_lines(ret_img, lines, thickness=1)\n",
    "                except:\n",
    "                    pass\n",
    "\n",
    "            return ret_img\n",
    "        \n",
    "\n",
    "    def update_target_model(self):\n",
    "        self.target_model.set_weights(self.model.get_weights())\n",
    "\n",
    "    # Get action from model using epsilon-greedy policy\n",
    "    def get_action(self, s_t):\n",
    "        if np.random.rand() <= self.epsilon:\n",
    "            #print(\"Return Random Value\")\n",
    "            #return random.randrange(self.action_size)\n",
    "            return np.random.uniform(-1,1)\n",
    "        else:\n",
    "            #print(\"Return Max Q Prediction\")\n",
    "            q_value = self.model.predict(s_t)\n",
    "            # Convert q array to steering value\n",
    "            return linear_unbin(q_value[0])\n",
    "\n",
    "    def replay_memory(self, state, action, reward, next_state, done):\n",
    "        self.memory.append((state, action, reward, next_state, done))\n",
    "        if self.epsilon > self.epsilon_min:\n",
    "            #self.epsilon *= self.epsilon_decay\n",
    "            self.epsilon -= (self.initial_epsilon - self.epsilon_min) / self.explore\n",
    "\n",
    "\n",
    "    def train_replay(self):\n",
    "        if len(self.memory) < self.train_start:\n",
    "            return\n",
    "        \n",
    "        batch_size = min(self.batch_size, len(self.memory))\n",
    "        minibatch = random.sample(self.memory, batch_size)\n",
    "\n",
    "        state_t, action_t, reward_t, state_t1, terminal = zip(*minibatch)\n",
    "        state_t = np.concatenate(state_t)\n",
    "        state_t1 = np.concatenate(state_t1)\n",
    "        targets = self.model.predict(state_t)\n",
    "        self.max_Q = np.max(targets[0])\n",
    "        target_val = self.model.predict(state_t1)\n",
    "        target_val_ = self.target_model.predict(state_t1)\n",
    "        for i in range(batch_size):\n",
    "            if terminal[i]:\n",
    "                targets[i][action_t[i]] = reward_t[i]\n",
    "            else:\n",
    "                a = np.argmax(target_val[i])\n",
    "                targets[i][action_t[i]] = reward_t[i] + self.discount_factor * (target_val_[i][a])\n",
    "\n",
    "        self.model.train_on_batch(state_t, targets)\n",
    "\n",
    "    def load_model(self, name):\n",
    "        self.model.load_weights(name)\n",
    "\n",
    "    # Save the model which is under training\n",
    "    def save_model(self, name):\n",
    "        self.model.save_weights(name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Utils Functions ##\n",
    "\n",
    "def linear_bin(a):\n",
    "    \"\"\"\n",
    "    Convert a value to a categorical array.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    a : int or float\n",
    "        A value between -1 and 1\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    list of int\n",
    "        A list of length 15 with one item set to 1, which represents the linear value, and all other items set to 0.\n",
    "    \"\"\"\n",
    "    a = a + 1\n",
    "    b = round(a / (2 / 14))\n",
    "    arr = np.zeros(15)\n",
    "    arr[int(b)] = 1\n",
    "    return arr\n",
    "\n",
    "\n",
    "def linear_unbin(arr):\n",
    "    \"\"\"\n",
    "    Convert a categorical array to value.\n",
    "\n",
    "    See Also\n",
    "    --------\n",
    "    linear_bin\n",
    "    \"\"\"\n",
    "    if not len(arr) == 15:\n",
    "        raise ValueError('Illegal array length, must be 15')\n",
    "    b = np.argmax(arr)\n",
    "    a = b * (2 / 14) - 1\n",
    "    return a\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Utils Functions ##\n",
    "\n",
    "def linear_bin(a):\n",
    "    \"\"\"\n",
    "    Convert a value to a categorical array.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    a : int or float\n",
    "        A value between -1 and 1\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    list of int\n",
    "        A list of length 15 with one item set to 1, which represents the linear value, and all other items set to 0.\n",
    "    \"\"\"\n",
    "    a = a + 1\n",
    "    b = round(a / (2 / 14))\n",
    "    arr = np.zeros(15)\n",
    "    arr[int(b)] = 1\n",
    "    return arr\n",
    "\n",
    "\n",
    "def linear_unbin(arr):\n",
    "    \"\"\"\n",
    "    Convert a categorical array to value.\n",
    "\n",
    "    See Also\n",
    "    --------\n",
    "    linear_bin\n",
    "    \"\"\"\n",
    "    if not len(arr) == 15:\n",
    "        raise ValueError('Illegal array length, must be 15')\n",
    "    b = np.argmax(arr)\n",
    "    a = b * (2 / 14) - 1\n",
    "    return a\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The true file name is donkey\n",
      "[]\n",
      "launch string is Null\n",
      "Now we build the model\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\envs\\gym6\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "connect  3f5120e04c3a4205aee86de9cc957a3a\n",
      "We finished building the model\n",
      "Now we build the model\n",
      "We finished building the model\n",
      "Episode:  0\n",
      "connect  bfa35f26e82642929a49b3182eeb0d0f\n",
      "ProtocolVersion  bfa35f26e82642929a49b3182eeb0d0f\n",
      "Loading generated_road\n",
      "connect  e0e39e64a5684a1ca4d335513c65d417\n",
      "EPISODE 0 TIMESTEP 30 / ACTION [-0.6875950116792204, 0.3] / REWARD 0.987017658 / EPISODE LENGTH 30 / Q_MAX  0\n",
      "EPISODE 0 TIMESTEP 60 / ACTION [-0.30563267197445887, 0.3] / REWARD 0.7800502 / EPISODE LENGTH 60 / Q_MAX  0\n",
      "episode: 0   memory length: 77   epsilon: 0.9924539999999967  episode length: 77\n",
      "Episode:  1\n",
      "connect  6c7fd668cdd54a69aee0b0a5272ae624\n",
      "ProtocolVersion  6c7fd668cdd54a69aee0b0a5272ae624\n",
      "Loading generated_road\n",
      "connect  befdb3e7e0ba4da98b79a516e13b1cde\n",
      "EPISODE 1 TIMESTEP 90 / ACTION [0.8501691687846964, 0.3] / REWARD 0.99771994 / EPISODE LENGTH 13 / Q_MAX  0\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\envs\\gym6\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "EPISODE 1 TIMESTEP 120 / ACTION [-0.7018874156191013, 0.3] / REWARD 0.583156 / EPISODE LENGTH 43 / Q_MAX  1.0892819\n",
      "episode: 1   memory length: 142   epsilon: 0.986083999999994  episode length: 65\n",
      "Episode:  2\n",
      "connect  4b1901f8ee9548bf8050446a268bfa72\n",
      "ProtocolVersion  4b1901f8ee9548bf8050446a268bfa72\n",
      "Loading generated_road\n",
      "connect  efec8b78af8e43efbd16925fbecd5c73\n",
      "EPISODE 2 TIMESTEP 150 / ACTION [-0.15181326943675266, 0.3] / REWARD 0.99466738 / EPISODE LENGTH 8 / Q_MAX  2.1231396\n",
      "EPISODE 2 TIMESTEP 180 / ACTION [-0.8704300768631785, 0.3] / REWARD 0.7788368 / EPISODE LENGTH 38 / Q_MAX  1.8773816\n",
      "episode: 2   memory length: 206   epsilon: 0.9798119999999912  episode length: 64\n",
      "Episode:  3\n",
      "connect  4faeb15e37d441acacfd17048d1ef5e3\n",
      "ProtocolVersion  4faeb15e37d441acacfd17048d1ef5e3\n",
      "Loading generated_road\n",
      "connect  a8c246d795654d50b87d57d82e719a96\n",
      "EPISODE 3 TIMESTEP 210 / ACTION [-0.7127390996881191, 0.3] / REWARD 0.999862698 / EPISODE LENGTH 4 / Q_MAX  1.8555903\n",
      "EPISODE 3 TIMESTEP 240 / ACTION [0.48258114299172905, 0.3] / REWARD 0.8621781399999999 / EPISODE LENGTH 34 / Q_MAX  2.3648822\n",
      "EPISODE 3 TIMESTEP 270 / ACTION [-0.8059811695861543, 0.3] / REWARD 0.88867014 / EPISODE LENGTH 64 / Q_MAX  2.521606\n",
      "episode: 3   memory length: 292   epsilon: 0.9713839999999876  episode length: 86\n",
      "Episode:  4\n",
      "connect  2e274bff7fc74b27aee73b8e06a7944e\n",
      "ProtocolVersion  2e274bff7fc74b27aee73b8e06a7944e\n",
      "Loading generated_road\n",
      "connect  048ab257c283455eb59a84c4e5f5bd0f\n",
      "EPISODE 4 TIMESTEP 300 / ACTION [-0.8192643665696082, 0.3] / REWARD 0.993855722 / EPISODE LENGTH 8 / Q_MAX  3.682067\n",
      "EPISODE 4 TIMESTEP 330 / ACTION [-0.5302030381393246, 0.3] / REWARD 0.96306148 / EPISODE LENGTH 38 / Q_MAX  3.2716947\n",
      "EPISODE 4 TIMESTEP 360 / ACTION [-0.4958258787450982, 0.3] / REWARD 0.7386186 / EPISODE LENGTH 68 / Q_MAX  3.3751152\n",
      "episode: 4   memory length: 372   epsilon: 0.9635439999999842  episode length: 80\n",
      "Episode:  5\n",
      "connect  507a99a5c0ab43ee92b9e09f6548348a\n",
      "ProtocolVersion  507a99a5c0ab43ee92b9e09f6548348a\n",
      "Loading generated_road\n",
      "connect  96681a6cb5d3451c9c23ad8164796ef3\n",
      "EPISODE 5 TIMESTEP 390 / ACTION [-0.9545079235299465, 0.3] / REWARD 0.992332544 / EPISODE LENGTH 18 / Q_MAX  4.336415\n",
      "EPISODE 5 TIMESTEP 420 / ACTION [0.6518620344548876, 0.3] / REWARD 0.87885704 / EPISODE LENGTH 48 / Q_MAX  4.164968\n",
      "EPISODE 5 TIMESTEP 450 / ACTION [-0.3991619437397609, 0.3] / REWARD 0.12837680000000007 / EPISODE LENGTH 78 / Q_MAX  4.0721025\n",
      "episode: 5   memory length: 453   epsilon: 0.9556059999999807  episode length: 81\n",
      "Episode:  6\n",
      "connect  054d4c25e5744335a3ce49fe769bacc8\n",
      "ProtocolVersion  054d4c25e5744335a3ce49fe769bacc8\n",
      "Loading generated_road\n",
      "connect  581bd8c5b5a748dc87af08258573d88d\n",
      "EPISODE 6 TIMESTEP 480 / ACTION [0.5843943355805221, 0.3] / REWARD 0.981640982 / EPISODE LENGTH 27 / Q_MAX  5.00507\n",
      "EPISODE 6 TIMESTEP 510 / ACTION [0.10626077960372449, 0.3] / REWARD 0.6996792000000001 / EPISODE LENGTH 57 / Q_MAX  5.142938\n",
      "episode: 6   memory length: 539   epsilon: 0.9471779999999771  episode length: 86\n",
      "Episode:  7\n",
      "connect  7d21b37e6911445d849ee9b0fcef481d\n",
      "ProtocolVersion  7d21b37e6911445d849ee9b0fcef481d\n",
      "Loading generated_road\n",
      "connect  7e0c2141b8cb4cb7bbe6d3a20a7ff8af\n",
      "EPISODE 7 TIMESTEP 540 / ACTION [0.18048059448682618, 0.3] / REWARD 0.99996937812 / EPISODE LENGTH 1 / Q_MAX  5.374971\n",
      "EPISODE 7 TIMESTEP 570 / ACTION [-0.023667382914305923, 0.3] / REWARD 0.989029428 / EPISODE LENGTH 31 / Q_MAX  5.885875\n",
      "episode: 7   memory length: 596   epsilon: 0.9415919999999747  episode length: 57\n",
      "Episode:  8\n",
      "connect  9afcf0490012477caf6f8240e08a86ae\n",
      "ProtocolVersion  9afcf0490012477caf6f8240e08a86ae\n",
      "Loading generated_road\n",
      "connect  dd7667f634d64baebac8dfe99692d414\n",
      "EPISODE 8 TIMESTEP 600 / ACTION [-0.6905983308077999, 0.3] / REWARD 0.9994550046 / EPISODE LENGTH 4 / Q_MAX  6.8135242\n",
      "EPISODE 8 TIMESTEP 630 / ACTION [0.41592070624093114, 0.3] / REWARD 0.93175858 / EPISODE LENGTH 34 / Q_MAX  6.384992\n",
      "EPISODE 8 TIMESTEP 660 / ACTION [0.31384766099515504, 0.3] / REWARD 0.90331408 / EPISODE LENGTH 64 / Q_MAX  5.8145237\n",
      "EPISODE 8 TIMESTEP 690 / ACTION [-0.8012228980375513, 0.3] / REWARD 0.992750704 / EPISODE LENGTH 94 / Q_MAX  6.664998\n",
      "episode: 8   memory length: 714   epsilon: 0.9300279999999697  episode length: 118\n",
      "Episode:  9\n",
      "connect  d8e28c4b66524eff8ef8733a00b2a7e9\n",
      "ProtocolVersion  d8e28c4b66524eff8ef8733a00b2a7e9\n",
      "Loading generated_road\n",
      "connect  a6b9c09b5c294c0facb452a363cc15f7\n",
      "EPISODE 9 TIMESTEP 720 / ACTION [0.7142857142857142, 0.3] / REWARD 0.9997642654 / EPISODE LENGTH 6 / Q_MAX  8.609226\n",
      "EPISODE 9 TIMESTEP 750 / ACTION [-0.056081700444539306, 0.3] / REWARD 0.91684408 / EPISODE LENGTH 36 / Q_MAX  7.3330727\n",
      "episode: 9   memory length: 774   epsilon: 0.9241479999999671  episode length: 60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(3288) wsgi starting up on http://0.0.0.0:9090\n",
      "C:\\Users\\Siddharth Bhola\\AppData\\Roaming\\Python\\Python36\\site-packages\\ipykernel_launcher.py:41: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (8, 8), input_shape=(80, 80, 4..., strides=(4, 4), padding=\"same\")`\n",
      "(3288) accepted ('127.0.0.1', 30980)\n",
      "C:\\Users\\Siddharth Bhola\\AppData\\Roaming\\Python\\Python36\\site-packages\\ipykernel_launcher.py:43: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (4, 4), strides=(2, 2), padding=\"same\")`\n",
      "C:\\Users\\Siddharth Bhola\\AppData\\Roaming\\Python\\Python36\\site-packages\\ipykernel_launcher.py:45: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), strides=(1, 1), padding=\"same\")`\n",
      "(3288) accepted ('127.0.0.1', 30982)\n",
      "(3288) accepted ('127.0.0.1', 30983)\n",
      "(3288) accepted ('127.0.0.1', 30986)\n",
      "(3288) accepted ('127.0.0.1', 30987)\n",
      "127.0.0.1 - - [10/Jun/2019 21:14:53] \"GET /socket.io/?EIO=4&transport=websocket HTTP/1.1\" 200 0 61.120148\n",
      "127.0.0.1 - - [10/Jun/2019 21:15:05] \"GET /socket.io/?EIO=4&transport=websocket HTTP/1.1\" 200 0 60.091298\n",
      "127.0.0.1 - - [10/Jun/2019 21:15:26] \"GET /socket.io/?EIO=4&transport=websocket HTTP/1.1\" 200 0 80.749260\n",
      "127.0.0.1 - - [10/Jun/2019 21:15:26] \"GET /socket.io/?EIO=4&transport=websocket HTTP/1.1\" 200 0 60.117770\n",
      "(3288) accepted ('127.0.0.1', 31020)\n",
      "(3288) accepted ('127.0.0.1', 31021)\n",
      "127.0.0.1 - - [10/Jun/2019 21:16:32] \"GET /socket.io/?EIO=4&transport=websocket HTTP/1.1\" 200 0 125.572102\n",
      "127.0.0.1 - - [10/Jun/2019 21:16:33] \"GET /socket.io/?EIO=4&transport=websocket HTTP/1.1\" 200 0 60.781755\n",
      "(3288) accepted ('127.0.0.1', 31031)\n",
      "(3288) accepted ('127.0.0.1', 31032)\n",
      "127.0.0.1 - - [10/Jun/2019 21:17:44] \"GET /socket.io/?EIO=4&transport=websocket HTTP/1.1\" 200 0 130.713513\n",
      "127.0.0.1 - - [10/Jun/2019 21:17:45] \"GET /socket.io/?EIO=4&transport=websocket HTTP/1.1\" 200 0 60.736103\n",
      "(3288) accepted ('127.0.0.1', 31051)\n",
      "(3288) accepted ('127.0.0.1', 31052)\n",
      "127.0.0.1 - - [10/Jun/2019 21:19:37] \"GET /socket.io/?EIO=4&transport=websocket HTTP/1.1\" 200 0 172.593327\n",
      "127.0.0.1 - - [10/Jun/2019 21:19:38] \"GET /socket.io/?EIO=4&transport=websocket HTTP/1.1\" 200 0 60.663771\n",
      "(3288) accepted ('127.0.0.1', 31058)\n",
      "(3288) accepted ('127.0.0.1', 31059)\n",
      "127.0.0.1 - - [10/Jun/2019 21:21:07] \"GET /socket.io/?EIO=4&transport=websocket HTTP/1.1\" 200 0 149.277989\n",
      "127.0.0.1 - - [10/Jun/2019 21:21:09] \"GET /socket.io/?EIO=4&transport=websocket HTTP/1.1\" 200 0 60.616533\n",
      "(3288) accepted ('127.0.0.1', 31080)\n",
      "(3288) accepted ('127.0.0.1', 31081)\n",
      "127.0.0.1 - - [10/Jun/2019 21:22:34] \"GET /socket.io/?EIO=4&transport=websocket HTTP/1.1\" 200 0 145.126996\n",
      "127.0.0.1 - - [10/Jun/2019 21:22:34] \"GET /socket.io/?EIO=4&transport=websocket HTTP/1.1\" 200 0 61.946737\n",
      "(3288) accepted ('127.0.0.1', 31098)\n",
      "(3288) accepted ('127.0.0.1', 31099)\n",
      "127.0.0.1 - - [10/Jun/2019 21:24:58] \"GET /socket.io/?EIO=4&transport=websocket HTTP/1.1\" 200 0 206.075243\n",
      "127.0.0.1 - - [10/Jun/2019 21:24:59] \"GET /socket.io/?EIO=4&transport=websocket HTTP/1.1\" 200 0 60.371296\n",
      "(3288) accepted ('127.0.0.1', 31105)\n",
      "(3288) accepted ('127.0.0.1', 31106)\n",
      "127.0.0.1 - - [10/Jun/2019 21:26:04] \"GET /socket.io/?EIO=4&transport=websocket HTTP/1.1\" 200 0 121.435359\n",
      "127.0.0.1 - - [10/Jun/2019 21:26:04] \"GET /socket.io/?EIO=4&transport=websocket HTTP/1.1\" 200 0 60.016991\n",
      "(3288) accepted ('127.0.0.1', 31155)\n",
      "(3288) accepted ('127.0.0.1', 31156)\n",
      "127.0.0.1 - - [10/Jun/2019 21:30:07] \"GET /socket.io/?EIO=4&transport=websocket HTTP/1.1\" 200 0 302.165983\n"
     ]
    }
   ],
   "source": [
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "sess = tf.Session(config=config)\n",
    "K.set_session(sess)\n",
    "\n",
    "env = gym.make(\"donkey-generated-roads-v0\")\n",
    "\n",
    "# Get size of state and action from environment\n",
    "state_size = (img_rows, img_cols, img_channels)\n",
    "action_size = env.action_space.n # Steering and Throttle\n",
    "\n",
    "agent = DQNAgent(state_size, action_size)\n",
    "\n",
    "throttle = 0.3 # Set throttle as constant value\n",
    "\n",
    "episodes = []\n",
    "\n",
    "if not agent.train:\n",
    "    print(\"Now we load the saved model\")\n",
    "    agent.load_model(\"./save_model/save_model.h5\")\n",
    "\n",
    "for e in range(EPISODES):\n",
    "\n",
    "    print(\"Episode: \", e)\n",
    "\n",
    "    done = False\n",
    "    obs = env.reset()\n",
    "\n",
    "    episode_len = 0\n",
    "\n",
    "    x_t = agent.process_image(obs)\n",
    "\n",
    "    s_t = np.stack((x_t,x_t,x_t,x_t),axis=2)\n",
    "    # In Keras, need to reshape\n",
    "    s_t = s_t.reshape(1, s_t.shape[0], s_t.shape[1], s_t.shape[2]) #1*80*80*4       \n",
    "\n",
    "    while not done:\n",
    "\n",
    "        # Get action for the current state and go one step in environment\n",
    "        steering = agent.get_action(s_t)\n",
    "        action = [steering, throttle]\n",
    "        next_obs, reward, done, info = env.step(action)\n",
    "\n",
    "        x_t1 = agent.process_image(next_obs)\n",
    "\n",
    "        x_t1 = x_t1.reshape(1, x_t1.shape[0], x_t1.shape[1], 1) #1x80x80x1\n",
    "        s_t1 = np.append(x_t1, s_t[:, :, :, :3], axis=3) #1x80x80x4\n",
    "\n",
    "        # Save the sample <s, a, r, s'> to the replay memory\n",
    "        agent.replay_memory(s_t, np.argmax(linear_bin(steering)), reward, s_t1, done)\n",
    "\n",
    "        if agent.train:\n",
    "            agent.train_replay()\n",
    "\n",
    "        s_t = s_t1\n",
    "        agent.t = agent.t + 1\n",
    "        episode_len = episode_len + 1\n",
    "        if agent.t % 30 == 0:\n",
    "            print(\"EPISODE\",  e, \"TIMESTEP\", agent.t,\"/ ACTION\", action, \"/ REWARD\", reward, \"/ EPISODE LENGTH\", episode_len, \"/ Q_MAX \" , agent.max_Q)\n",
    "\n",
    "        if done:\n",
    "\n",
    "            # Every episode update the target model to be same with model\n",
    "            agent.update_target_model()\n",
    "\n",
    "            episodes.append(e)\n",
    "\n",
    "\n",
    "            # Save model for each episode\n",
    "            if agent.train:\n",
    "                agent.save_model(\"save_model/save_model.h5\")\n",
    "\n",
    "            print(\"episode:\", e, \"  memory length:\", len(agent.memory),\n",
    "                  \"  epsilon:\", agent.epsilon, \" episode length:\", episode_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
